---
title: "Reporte"
format: 
  html:
    self-contained: true
editor: visual
author: "Agustin Lehmann, Gabriel Szerman, Ernesto Mercado, Ignacio Gallego"
---

# Imports:

```{r }
#| output: false
require(tidyverse)
require(knitr)
require(Metrics) #install.packages("Metrics")
require(rpart) #install.packages("rpart")
require(caret) #install.packages("caret")
require(class) #install.packages("class")


load("./tp2.RData")
theme_set(theme_classic())
```

Inicialmente contaremos feriados como dias laborables.

```{r}
clima_ecobici = clima_ecobici %>%
  mutate(
    dia_laborable = if_else(lubridate::wday(date)==1| lubridate::wday(date)==7,"No Laborable","Laborable")
  )

kable(head(clima_ecobici))
```

# Parte 1: Eco bicis

## EDA:

### Día Laborable

```{r}
clima_ecobici %>%
  group_by(dia_laborable) %>%
  summarise(
    prom_viajes = mean(n)
  )%>%
  ggplot(aes(y=prom_viajes, x=dia_laborable))+
  geom_col(fill='darkcyan') + 
  labs(
    title = "Promedio de viajes por día laborable o no",
    y = "Promedio de viajes",
    x = "Tipo de día"
  )
```

Se puede ver que hay muchos mas viajes los dias laborables. La tomare en consideracion para el resto de los analisis

### Precipitación

```{r}
clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
  ) %>%
  ggplot(aes(x=lluvias, y=n))+
  geom_boxplot(fill="darkcyan")+
  labs(
    title = "Cant. Viajes segun precipitación",
    x= "Precipitación (mm)",
    y= "Viajes",
    legend=""
  ) +
  theme(legend.title=element_blank()) 
```

Se puede ver que hay menos promedio de viajes por dia (hasta \~30% menos) si llueve y si llueve mucho hay muchisimos menos.

```{r }
#| echo: false
kable(clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
      n_laborable = if_else(dia_laborable=="Laborable", n,0),
  ) %>%
  group_by(lluvias)%>%
  summarise(
    prom_viajes_por_dia = mean(n),
  ))
```

```{r}
clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
  ) %>% 
  filter(dia_laborable == "Laborable") %>%
  ggplot(aes(x=lluvias, y=n))+
  geom_boxplot(fill="#F8766D")+
  labs(
    title = "Cant. Viajes segun precipitación",
    subtitle = "Días Laborables",
    x= "Precipitación (mm)",
    y= "Viajes",
    legend=""
  ) +
  theme(legend.title=element_blank()) 
```

```{r}
clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
  ) %>% 
  filter(dia_laborable != "Laborable") %>%
  ggplot(aes(x=lluvias, y=n))+
  geom_boxplot(fill="#619CFF")+
  labs(
    title = "Cant. Viajes segun precipitación",
    subtitle = "Días No Laborables",
    x= "Precipitación (mm)",
    y= "Viajes",
    legend=""
  ) +
  theme(legend.title=element_blank()) 
```

La tendencia se muestra indistinta de si es un día laboral o no, hay que destacar que hay algunos dias que son outliers, por encima para los dias No Laborables y por debajo para los Laborables que podrian llegar a afectar al modelo.

### Presión atmosférica

```{r}
clima_ecobici %>%
  ggplot(aes(x=pres,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Presión Atmosféroca (hPa)",
    title = "Cant. de Viajes en función de la Presión"
  )+
  theme(legend.title=element_blank()) 
```

Se puede ver que si el día es laborable la presión afecta la cantidad de viajes de forma creciente y en los días no laborables también lo hace pero de forma muy leve.

### Temp. Mínima

```{r}
clima_ecobici %>%
  ggplot(aes(x=tmin,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Temp. Mínima (°C)",
    title = "Cant. de Viajes en función de la Temp. Mínima"
  )+
  theme(legend.title=element_blank()) 
```

Creciente para ambas pero mucho mas leve que como ocurría con la presión.

### Temp. Promedio

```{r}
clima_ecobici %>%
  ggplot(aes(x=tavg,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Temp. Promedio (°C)",
    title = "Cant. de Viajes en función de la Temp. Promedio"
  )+
  theme(legend.title=element_blank()) 
```

Creciente con una menor pendiente que la presión pero mayor a tmin

### Temp. Máxima

```{r}
clima_ecobici %>%
  ggplot(aes(x=tmax,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Temp. Máxima (°C)",
    title = "Cant. de Viajes en función de la Temp. Máxima"
  )+
  theme(legend.title=element_blank()) 
```

Igual que la temperatura promedio, la cantidad de viajes es creciente.

### Velocidad del Viento

```{r}
clima_ecobici %>%
  ggplot(aes(x=wspd,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  theme(legend.title=element_blank()) +
  labs(
    x="Velocidad del Viento (km/h)",
    y = "Cantidad de viajes",
    title = "Cant. de Viajes en función de la Vel. del Viento"
  )
```

Afecta a los dias No laborables de forma creciente y a los laborables de forma decreciente (aunque con mucha varianza)

## Conclusión del EDA

[Cosas importantes que sacamos del EDA]{.underline}:

-   Hay mas viajes los Días Laborales.

-   A mayor precipitación, menos Viajes.

-   La presión atmosférica, la temperatura promedio, máxima y mínima afectan de forma creciente a la cantidad de viajes.

## Modelos:

Como vimos en el EDA las columnas mas importantes parecen ser Dia Laborable, Precipitación y Presión atmosferica y dia laborable siendo la mas importante.

Vamos a hacer diferentes experimentos con la columnas

-   Día laborable con Presión

-   Dia Laborable con Precipitación

-   Dia Laborable con Precipitación (pero modificada como un boleano de si llueve o no)

-   Dia Laborable con Precipitacion (pero modificada como segmentos bazados en la cantidad de precipitacion)

De esos modelos eligiremos el que tenga mejor r2 y si hay empate el de mejor RMSE

### Funciones para probar cada modelo

```{r}
r2 = function(y_actual,y_predict){
  return(cor(y_actual,y_predict)^2)
}

#retorna los resultados del modelo
eval_formula = function(nombre_modelo, formula, x_train, x_test, y_train, y_test){
  modelo = lm({{formula}}, data = x_train)
  train_preds = predict(modelo, x_train)
  test_preds = predict(modelo, x_test)
  
  return(
    data.frame(
      nombre_exp = nombre_modelo,
      formula = formula,
      train_RMSE = rmse(y_train, train_preds),
      train_r2 = r2(y_train, train_preds),
      test_RMSE = rmse(y_test, test_preds),
      test_r2 = r2(y_test, test_preds)
    )
  )
}

#retorna un dataframe con los nombres de las columnas a usar normalizados
#asi no escribimos tanto
preprocess_df = function(df, target, colum_1, colum_2){
  return(
    df %>%
      # tuve que poner el all_of pq me tiraba warnings
      select(all_of({{target}}), all_of({{colum_1}}), all_of({{colum_2}})) %>%
      rename(
        "y"=target, 
        "col_1"=colum_1, 
        "col_2"=colum_2)
  )
}

#creo la lista de formulas
formulas = c(
  "y ~ col_1", #caso mas simples
  "y ~ col_2",
  "y ~ col_1 + col_2",  #combinaciones
  "y ~ col_1 * col_2",
  "y ~ col_1 * col_2 + col_1",
  "y ~ col_1 * col_2 + col_2",
  "y ~ col_1 * col_2 + col_1 + col_2"
)

#Creo la funcion que engloba todo
probar_experimento = function(nombre, seed, target, x1, x2,df){
  data = preprocess_df(df, target, x1, x2)
  
  set.seed(seed)

  #train test split
  data$index = 1:length(data$y)
  train = data %>% sample_frac(0.8)
  test = data %>% anti_join(train, by="index")

  # guardo los resultados en una tabla
  res = data.frame(
      nombre_exp = NA,
      formula = NA,
      train_RMSE = NA,
      train_r2 = NA,
      test_RMSE = NA,
      test_r2 = NA,
      seed = NA,
      col_1 = NA,
      col_2 = NA
    ) %>% filter(!is.na(seed))

  #pruebo cada forumula
  for(formula in formulas){
    exp_res = eval_formula(
      nombre, formula, 
      train,
      test,
      train$y,
      test$y
      )
    
    exp_res$seed = seed
    exp_res$col_1 = x1
    exp_res$col_2 = x2
    res = rbind(res, exp_res)
  }
  
  #devuelvo los resultados
  return(res)
}
```

### Creando las diferentes variables de lluvia

```{r}
df = clima_ecobici %>%
  mutate(
    lluvias_binned = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
    llovio = if_else(prcp > 0, T, F)
  )
```

### Guardaremos todos los resultados en un dataframe

```{r}

resultados = data.frame(
      nombre_exp = NA,
      formula = NA,
      train_RMSE = NA,
      train_r2 = NA,
      test_RMSE = NA,
      test_r2 = NA,
      seed = NA
) %>% filter(!is.na(seed))

seed_ = 42

resultados = rbind(resultados, probar_experimento(
  "Dia laborable Presion",
  seed_, "n", "dia_laborable", "pres", df))
resultados = rbind(resultados, probar_experimento(
  "Dia laborable pptacion",
  seed_, "n", "dia_laborable", "prcp", df))
resultados = rbind(resultados, probar_experimento(
  "Dia laborable llueve o no",
  seed_, "n", "dia_laborable", "llovio", df))
resultados = rbind(resultados, probar_experimento(
  "Dia laborable lluvia binned",
  seed_, "n", "dia_laborable", "lluvias_binned", df))
```

```{r}
kable(resultados %>% arrange(-test_r2))
```

```{r}

```

## Resultados:

# Parte 2: Fake news

## EDA:

```{r}
df = fake_news%>%
  select(type,title_has_excl,title_words, negative)

kable(head(df))
```

### Título con simbolo de exclamación

```{r}
df %>%
  mutate(
    exlamacion = if_else(title_has_excl,'Tiene Signo de Exclamación', 'No Tiene Signo de Exclamación')
  ) %>%
  ggplot(aes(fill=type,x=exlamacion)) +
  theme(legend.title=element_blank()) +
  labs(
    x="",
    y = "Cantidad de Noticias",
    title = "Cantidad de noticias con simbolos de exclamación en el título"
  ) +
  geom_bar()
```

Podemos ver que la mayor parte de las noticias con titulos que tienen signos de exclamación son Fake.

### Cantidad de palabras en el título

```{r}
df %>%
  ggplot(aes(x=type, y=title_words, fill=type)) +
  geom_boxplot() +
  labs(
    title ="Cantidad de palabras en el título",
    x = "",
    y = "Cantidad de palabras"
  ) +
  theme(
    legend.position = "none"
  )
```

Las Fake news suelen tener mas palabras en el título.

### % de palabras negativas

```{r}
df %>%
  ggplot(aes(x=type, y=negative, fill=type))+
  geom_boxplot() +
  labs(
    title ="% de palabras negativas",
    x = "",
    y = "% de palabras negativas"
  ) +
  theme(
    legend.position = "none"
  )
```

Las Fake news suelen tener mas palabras negativas que las reales.

## Entrenamos el modelo con Decision Tree:

```{r}

set.seed(seed_)

# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # El 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]




# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))



# Definimos una función para evaluar modelos con diferentes combinaciones de características
evaluate_feature_combinations <- function(data, target_col, feature_cols) {
  result <- list()
  
  for (k in 1:length(feature_cols)) {
    combinations <- combn(feature_cols, k)
    
    for (i in 1:ncol(combinations)) {
      selected_features <- c(target_col, combinations[, i])
      train_data <- data[, selected_features]
      
      
      # Entrenamos el modelo
      model <- rpart(paste(target_col, "~", paste(combinations[, i], collapse = " + "), sep = ""), data = train_data)
      
      
      
      # Predecimos
      predictions <- predict(model, data, type = "class")
      
      
      
      # Evaluamos el modelo
      confusion_matrix <- confusionMatrix(predictions, data[, target_col])
      
      
      
      # Obtenemos la matriz de confusión y precisión
      result[[paste(combinations[, i], collapse = "-")]] <- list(
        ConfusionMatrix = confusion_matrix$table,
        Accuracy = confusion_matrix$overall["Accuracy"]
      )
    }
  }
  
  return(result)
}






# Definimos los nombres de las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"  # Cambiar a la columna "type" que deseas predecir

# Llamamos a la función para evaluar las combinaciones de características en el conjunto de prueba
results <- evaluate_feature_combinations(test_data, target_column, feature_columns)
```

## Resultados Decision Tree:

```{r}
# Imprimimos los resultados (matriz de confusión y precisión) de decision tree
for (combination_name in names(results)) {
  cat("Combinación:", combination_name, "\n")
  print(results[[combination_name]]$ConfusionMatrix)
  cat("Accuracy:", results[[combination_name]]$Accuracy, "\n\n")
}

```

Combinaciones de columna con mayor accuracy (0.74):

-   title_words,

-   title_has_excl-title_words,

-   title-words-negative

```{=html}
<!-- -->
```
-   title_has_excl - title_words - negative

Por el contexto, preferimos minimizar la cantidad de falsos negativos (Que haya noticias reales que sean detectadas como fake news no es tanto problema, pero si es un problema que haya fake news que sean detectadas como reales y permitida su circulación)

En este caso particular, las 4 posibilidades tienen la misma accuracy y la misma matriz de confusión asi que elgiremos el último caso que es la combinación de las 3 columnas

-   title_has_excl - title_words - negative

## 

## Entrenamos el modelo con KNN:

```{r}

set.seed(seed_)

# Cargamos la librería para KNN
library(class)

# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # Seleccionamos el 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]

# Eliminamos filas con valores faltantes en ambos conjuntos
train_data <- na.omit(train_data)
test_data <- na.omit(test_data)

# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))

# Definimos una función para evaluar modelos KNN con diferentes combinaciones de características y k
evaluate_feature_combinations_knn <- function(train_data, test_data, target_col, feature_cols, k_values) {
  result <- list()
  
  for (k in 1:length(feature_cols)) {
    combinations <- combn(feature_cols, k)
    
    for (i in 1:ncol(combinations)) {
      selected_features <- c(target_col, combinations[, i])
      
      for (k_value in k_values) {
        # Entrenamos el modelo KNN
        model <- knn(train_data[, selected_features][-1], test_data[, selected_features][-1], train_data[, selected_features][, 1], k = k_value)
        
        # Evaluamos el modelo
        confusion_matrix <- table(model, test_data[, selected_features][, 1])
        
        # Calculamos la precisión
        accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
        
        # Almacenamos resultados
        result[[paste(combinations[, i], collapse = "-")]]$k_value <- list(
          ConfusionMatrix = confusion_matrix,
          Accuracy = accuracy
        )
      }
    }
  }
  
  return(result)
}

# Definimos las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"

# Definimos los valores de k que deseamos probar
k_values_to_test <- c(3, 5, 7, 9, 11)

# Llamamos a la función para evaluar combinaciones de características y diferentes valores de k en el conjunto de prueba con KNN
results_knn <- evaluate_feature_combinations_knn(train_data, test_data, target_column, feature_columns, k_values_to_test)





```

## Resultados KNN:

```{r}
# Imprimimos los resultados (matriz de confusión y precisión) de KNN para cada combinación de características y k
for (combination_name in names(results_knn)) {
  for (k_value in k_values_to_test) {
    cat("Combinación:", combination_name, "\n")
    cat("Valor de k:", k_value, "\n")
    print(results_knn[[combination_name]]$k_value$ConfusionMatrix)
    cat("Accuracy:", results_knn[[combination_name]]$k_value$Accuracy, "\n\n")
  }
}
```

La combinación de columnas title_has_excl - title_words nos dió un accuracy de 0.72 . Para todos los valores de k probados, se obtiene la misma matriz de confusión. Tomaremos el valor k=3

## Probabilidad de que articulo sea fake news:

Debido a que el algoritmo decision-tree mostró un mejor accuracy, decidimos utilizarlo para predecir la probabilidad de que un artículo sea fake si tiene 0 signos de exclamación, 15 palabras en el título y 6% de palabras con connotación negativa

```{r}
set.seed(seed_)

# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # El 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]




# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
```

```{r}


# Convrtimos 'title_has_excl' en tipo numérico
train_data$title_has_excl <- as.numeric(train_data$title_has_excl)


# Entrenamos el modelo utilizando solo las 3 columnas que queremos
model <- rpart(type ~ title_has_excl + title_words + negative, data = train_data)
# Creamos un nuevo conjunto de datos con las características del nuevo artículo
new_article <- data.frame(
  title_has_excl = 0,  # No tiene signos de exclamación
  title_words = 15,    # 15 palabras en el título
  negative = 0.06      # 6% de palabras con connotaciones negativas
)

# Utilizamos el modelo de árbol de decisión para predecir la clase del nuevo artículo
predicted_class <- predict(model, new_article, type = "class")

# Calculamos la probabilidad de que el artículo sea "fake-news"
predicted_probability <- predict(model, new_article, type = "prob")

fake_news_probability <- predicted_probability[1, "fake"]

# Imprimir la clase predicha y la probabilidad
cat("Clase predicha:", predicted_class, "\n")
cat("Probabilidad de ser 'fake-news':", fake_news_probability, "\n")
```

La probabilidad de que el artículo sea fake con 0 signos de exlamación, 15 palabras en el título y 6% de palabras con connotación negativa es de 64%
