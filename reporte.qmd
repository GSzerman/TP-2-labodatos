---
title: "Reporte"
format: 
  html:
    self-contained: true
editor: visual
author: "Agustin Lehmann, Gabriel Szerman, Ernesto Mercado, Ignacio Gallego"
---

# Imports:

```{r }
#| output: false
require(tidyverse)
require(knitr)
require(Metrics) #install.packages("Metrics")
require(rpart) #install.packages("rpart")
require(caret) #install.packages("caret")
require(class) #install.packages("class")
require(rpart.plot)

load("./tp2.RData")
theme_set(theme_classic())
```

Inicialmente contaremos feriados como dias laborables.

```{r}
clima_ecobici = clima_ecobici %>%
  mutate(
    dia_laborable = if_else(lubridate::wday(date)==1| lubridate::wday(date)==7,"No Laborable","Laborable")
  )

kable(head(clima_ecobici))
```

# Parte 1: Eco bicis

## EDA:

### Día Laborable

```{r}
clima_ecobici %>%
  group_by(dia_laborable) %>%
  summarise(
    prom_viajes = mean(n)
  )%>%
  ggplot(aes(y=prom_viajes, x=dia_laborable))+
  geom_col(fill='darkcyan') + 
  labs(
    title = "Promedio de viajes por día laborable o no",
    y = "Promedio de viajes",
    x = "Tipo de día"
  )
```

Se puede ver que hay muchos mas viajes los dias laborables. La tomare en consideracion para el resto de los analisis

### Precipitación

```{r}
clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
  ) %>%
  ggplot(aes(x=lluvias, y=n))+
  geom_boxplot(fill="darkcyan")+
  labs(
    title = "Cant. Viajes segun precipitación",
    x= "Precipitación (mm)",
    y= "Viajes",
    legend=""
  ) +
  theme(legend.title=element_blank()) 
```

Se puede ver que hay menos promedio de viajes por dia (hasta \~30% menos) si llueve y si llueve mucho hay muchisimos menos.

```{r }
#| echo: false
kable(clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
      n_laborable = if_else(dia_laborable=="Laborable", n,0),
  ) %>%
  group_by(lluvias)%>%
  summarise(
    prom_viajes_por_dia = mean(n),
  ))
```

```{r}
clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
  ) %>% 
  filter(dia_laborable == "Laborable") %>%
  ggplot(aes(x=lluvias, y=n))+
  geom_boxplot(fill="#F8766D")+
  labs(
    title = "Cant. Viajes segun precipitación",
    subtitle = "Días Laborables",
    x= "Precipitación (mm)",
    y= "Viajes",
    legend=""
  ) +
  theme(legend.title=element_blank()) 
```

```{r}
clima_ecobici %>%
  mutate(
      lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
  ) %>% 
  filter(dia_laborable != "Laborable") %>%
  ggplot(aes(x=lluvias, y=n))+
  geom_boxplot(fill="#619CFF")+
  labs(
    title = "Cant. Viajes segun precipitación",
    subtitle = "Días No Laborables",
    x= "Precipitación (mm)",
    y= "Viajes",
    legend=""
  ) +
  theme(legend.title=element_blank()) 
```

La tendencia se muestra indistinta de si es un día laboral o no, hay que destacar que hay algunos dias que son outliers, por encima para los dias No Laborables y por debajo para los Laborables que podrian llegar a afectar al modelo.

### Presión atmosférica

```{r}
clima_ecobici %>%
  ggplot(aes(x=pres,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Presión Atmosféroca (hPa)",
    title = "Cant. de Viajes en función de la Presión"
  )+
  theme(legend.title=element_blank()) 
```

Se puede ver que si el día es laborable la presión afecta la cantidad de viajes de forma creciente y en los días no laborables también lo hace pero de forma muy leve.

### Temp. Mínima

```{r}
clima_ecobici %>%
  ggplot(aes(x=tmin,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Temp. Mínima (°C)",
    title = "Cant. de Viajes en función de la Temp. Mínima"
  )+
  theme(legend.title=element_blank()) 
```

Creciente para ambas pero mucho mas leve que como ocurría con la presión.

### Temp. Promedio

```{r}
clima_ecobici %>%
  ggplot(aes(x=tavg,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Temp. Promedio (°C)",
    title = "Cant. de Viajes en función de la Temp. Promedio"
  )+
  theme(legend.title=element_blank()) 
```

Creciente con una menor pendiente que la presión pero mayor a tmin

### Temp. Máxima

```{r}
clima_ecobici %>%
  ggplot(aes(x=tmax,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  labs(
    y = "Cantidad de viajes",
    x = "Temp. Máxima (°C)",
    title = "Cant. de Viajes en función de la Temp. Máxima"
  )+
  theme(legend.title=element_blank()) 
```

Igual que la temperatura promedio, la cantidad de viajes es creciente.

### Velocidad del Viento

```{r}
clima_ecobici %>%
  ggplot(aes(x=wspd,y=n,color=dia_laborable))+
  geom_smooth(se=T, method = 'lm') +
  geom_point() +
  theme(legend.title=element_blank()) +
  labs(
    x="Velocidad del Viento (km/h)",
    y = "Cantidad de viajes",
    title = "Cant. de Viajes en función de la Vel. del Viento"
  )
```

Afecta a los dias No laborables de forma creciente y a los laborables de forma decreciente (aunque con mucha varianza)

## Conclusión del EDA

[Cosas importantes que sacamos del EDA]{.underline}:

-   Hay mas viajes los Días Laborales.

-   A mayor precipitación, menos Viajes.

-   La presión atmosférica, la temperatura promedio, máxima y mínima afectan de forma creciente a la cantidad de viajes.

## Modelos:

Como vimos en el EDA las columnas mas importantes parecen ser Dia Laborable, Precipitación y Presión atmosferica y dia laborable siendo la mas importante.

Vamos a hacer diferentes experimentos con la columnas

-   Día laborable con Presión

-   Dia Laborable con Precipitación

-   Dia Laborable con Precipitación (pero modificada como un boleano de si llueve o no)

-   Dia Laborable con Precipitacion (pero modificada como segmentos bazados en la cantidad de precipitacion)

De esos modelos eligiremos el que tenga mejor r2 y si hay empate el de mejor RMSE

### Funciones para probar cada modelo

```{r}
r2 = function(y_actual,y_predict){
  return(cor(y_actual,y_predict)^2)
}

#retorna los resultados del modelo
eval_formula = function(nombre_modelo, formula, x_train, x_test, y_train, y_test){
  modelo = lm({{formula}}, data = x_train)
  train_preds = predict(modelo, x_train)
  test_preds = predict(modelo, x_test)
  
  return(
    data.frame(
      nombre_exp = nombre_modelo,
      formula = formula,
      train_RMSE = rmse(y_train, train_preds),
      train_r2 = r2(y_train, train_preds),
      test_RMSE = rmse(y_test, test_preds),
      test_r2 = r2(y_test, test_preds)
    )
  )
}

#retorna un dataframe con los nombres de las columnas a usar normalizados
#asi no escribimos tanto
preprocess_df = function(df, target, colum_1, colum_2){
  return(
    df %>%
      # tuve que poner el all_of pq me tiraba warnings
      select(all_of({{target}}), all_of({{colum_1}}), all_of({{colum_2}})) %>%
      rename(
        "y"=target, 
        "col_1"=colum_1, 
        "col_2"=colum_2)
  )
}

#creo la lista de formulas
formulas = c(
  "y ~ col_1", #caso mas simples
  "y ~ col_2",
  "y ~ col_1 + col_2",  #combinaciones
  "y ~ col_1 * col_2",
  "y ~ col_1 * col_2 + col_1",
  "y ~ col_1 * col_2 + col_2",
  "y ~ col_1 * col_2 + col_1 + col_2"
)

#Creo la funcion que engloba todo
probar_experimento = function(nombre, seed, target, x1, x2,df){
  data = preprocess_df(df, target, x1, x2)
  
  set.seed(seed)

  #train test split
  data$index = 1:length(data$y)
  train = data %>% sample_frac(0.8)
  test = data %>% anti_join(train, by="index")

  # guardo los resultados en una tabla
  res = data.frame(
      nombre_exp = NA,
      formula = NA,
      train_RMSE = NA,
      train_r2 = NA,
      test_RMSE = NA,
      test_r2 = NA,
      seed = NA,
      col_1 = NA,
      col_2 = NA
    ) %>% filter(!is.na(seed))

  #pruebo cada forumula
  for(formula in formulas){
    exp_res = eval_formula(
      nombre, formula, 
      train,
      test,
      train$y,
      test$y
      )
    
    exp_res$seed = seed
    exp_res$col_1 = x1
    exp_res$col_2 = x2
    res = rbind(res, exp_res)
  }
  
  #devuelvo los resultados
  return(res)
}
```

### Creando las diferentes variables de lluvia

```{r}
df = clima_ecobici %>%
  mutate(
    lluvias_binned = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
    llovio = if_else(prcp > 0, T, F)
  )
```

### Guardaremos todos los resultados en un dataframe

```{r}
#|ooutput: F
resultados = data.frame(
      nombre_exp = NA,
      formula = NA,
      train_RMSE = NA,
      train_r2 = NA,
      test_RMSE = NA,
      test_r2 = NA,
      seed = NA
) %>% filter(!is.na(seed))

seed_ = 42

resultados = rbind(resultados, probar_experimento(
  "Dia laborable Presion",
  seed_, "n", "dia_laborable", "pres", df))
resultados = rbind(resultados, probar_experimento(
  "Dia laborable pptacion",
  seed_, "n", "dia_laborable", "prcp", df))
resultados = rbind(resultados, probar_experimento(
  "Dia laborable llueve o no",
  seed_, "n", "dia_laborable", "llovio", df))
resultados = rbind(resultados, probar_experimento(
  "Dia laborable lluvia binned",
  seed_, "n", "dia_laborable", "lluvias_binned", df))
```

```{r}
kable(resultados %>% arrange(-test_r2))
```

## Resultados:

Los R cuadrados dieron muy bajos, veamos si lo podemos mejorar cargando los feriados (consideramos trasladables como puente, osea que arrastro a lo mas cercano al finde semana (viernes, si cayo jueves o lunes, si cayo martes) o muevo al viernes(si cae miercoles) para que sea finde largo.

```{r}
feriados = c(
  "2022-01-01",
  "2022-02-28",
  "2022-03-01",
  "2022-03-24",
  "2022-04-02",
  "2022-04-14",
  "2022-04-15",
  "2022-05-01",
  "2022-05-18",
  "2022-05-25",
  "2022-06-17",
  "2022-06-20",
  "2022-07-09",
  "2022-08-15",
  "2022-10-07",
  "2022-10-10",
  "2022-11-20",
  "2022-11-21",
  "2022-12-08",
  "2022-12-09",
  "2022-12-25"
)
```

```{r}
df = clima_ecobici %>%
  mutate(
    lluvias_binned = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
    llovio = if_else(prcp > 0, T, F),
    dia_laborable = if_else(date %in% feriados, "No Laborable",dia_laborable)
  )
```

```{r}
resultados = rbind(resultados, probar_experimento(
  "Feriados Dia laborable Presion",
  seed_, "n", "dia_laborable", "pres", df))
resultados = rbind(resultados, probar_experimento(
  "Feriados Dia laborable pptacion",
  seed_, "n", "dia_laborable", "prcp", df))
resultados = rbind(resultados, probar_experimento(
  "Feriados Dia laborable llueve o no",
  seed_, "n", "dia_laborable", "llovio", df))
resultados = rbind(resultados, probar_experimento(
  "Feriados Dia laborable lluvia binned",
  seed_, "n", "dia_laborable", "lluvias_binned", df))
```

```{r}
kable(resultados %>% arrange(-test_r2))
```

Mejoró muchisimo el mejor modelo termino siendo dia laborable \* llovio (si bien hay empate elejimos el mas simple) con 0.74 de r2.

### Grafico del mejor modelo

```{r}
  set.seed(42)
  
  df = clima_ecobici %>%
  mutate(
    lluvias_binned = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
    llovio = if_else(prcp > 0, T, F),
    dia_laborable = if_else(date %in% feriados, "No Laborable",dia_laborable)
  )
  
  #train test split
  df$index = 1:length(df$n)
  train = df %>% sample_frac(0.8)
  test = df %>% anti_join(train, by="index")
  
  modelo = lm(n ~ dia_laborable * llovio, data = train)
```

```{r}
summary(modelo)
```

Segun los coef:

-   si el dia no es laborable tiene pendiente negativa, coincide con lo que vimos en el EDA

-   si llovio tambien tiene pendiente negativa y coincide con el EDA

-   si no es laborable y llueve tiene pendiente positiva, este es raro ya que no coincide con el EDA.

Como tenemos 2 variables booleanas vamos a graficar n por cada una de las combinaciones de coeficientes y comparar los predicts con los reales.

```{r}
intercept = summary(modelo)$coefficients[1]
dia_no_laborable = summary(modelo)$coefficients[2]
llovio_t = summary(modelo)$coefficients[3]
dia_no_laborable_llovio_t = summary(modelo)$coefficients[4]

df %>% mutate(
    preds = predict(modelo, df)
  ) %>%
  ggplot()+
  geom_point(aes(y=n, x=llovio, shape="Real"),color="darkcyan",alpha=0.3) +
  geom_abline(aes(slope = dia_no_laborable, intercept = intercept, color="Dia No Laborable")) +
  geom_abline(aes(slope = llovio_t, intercept = intercept,color="Llovio = T")) +
  geom_abline(aes(slope = dia_no_laborable_llovio_t, intercept = intercept,color="Dia No Laborable + LLovio = T")) +
  geom_point(aes(y=preds, x=llovio, shape="Preds"),color="darkorange",alpha=0.3) +
  labs(
    title= "Cantidad de viajes x llovio"
  )
```

por dia laborable

```{r}
df %>% mutate(
    preds = predict(modelo, df)
  ) %>%
  ggplot()+
  geom_point(aes(y=n, x=dia_laborable, shape="Real"),color="darkcyan",alpha=0.3) +
  geom_abline(aes(slope = dia_no_laborable, intercept = intercept, color="Dia No Laborable")) +
  geom_abline(aes(slope = llovio_t, intercept = intercept,color="Llovio = T")) +
  geom_abline(aes(slope = dia_no_laborable_llovio_t, intercept = intercept,color="Dia No Laborable + LLovio = T")) +
  geom_point(aes(y=preds, x=dia_laborable, shape="Preds"),color="darkorange",alpha=0.3) +
  labs(
    title= "Cantidad de viajes x dia_laborable"
  )
```

veamos dia no laborable y llovio = True tmb

```{r}
df %>% mutate(
    preds = predict(modelo, df),
    dia_lab_x_llovio = if_else(
      dia_laborable == "No Laborable" & llovio, T, F
    )
  ) %>%
  ggplot()+
  geom_point(aes(y=n, x=dia_lab_x_llovio, shape="Real"),color="darkcyan",alpha=0.3) +
  geom_abline(aes(slope = dia_no_laborable, intercept = intercept, color="Dia No Laborable")) +
  geom_abline(aes(slope = llovio_t, intercept = intercept,color="Llovio = T")) +
  geom_abline(aes(slope = dia_no_laborable_llovio_t, intercept = intercept,color="Dia No Laborable + LLovio = T")) +
  geom_point(aes(y=preds, x=dia_lab_x_llovio, shape="Preds"),color="darkorange",alpha=0.3) +
  labs(
    title= "Cantidad de viajes x dia_no_lab_x_llovio"
  )
```

# Parte 2: Fake news

## EDA:

```{r}
df = fake_news%>%
  select(type,title_has_excl,title_words, negative)

kable(head(df))
```

### Título con simbolo de exclamación

```{r}
df %>%
  mutate(
    exlamacion = if_else(title_has_excl,'Tiene Signo de Exclamación', 'No Tiene Signo de Exclamación')
  ) %>%
  ggplot(aes(fill=type,x=exlamacion)) +
  theme(legend.title=element_blank()) +
  labs(
    x="",
    y = "Cantidad de Noticias",
    title = "Cantidad de noticias con simbolos de exclamación en el título"
  ) +
  geom_bar()
```

Podemos ver que la mayor parte de las noticias con titulos que tienen signos de exclamación son Fake.

### Cantidad de palabras en el título

```{r}
df %>%
  ggplot(aes(x=type, y=title_words, fill=type)) +
  geom_boxplot() +
  labs(
    title ="Cantidad de palabras en el título",
    x = "",
    y = "Cantidad de palabras"
  ) +
  theme(
    legend.position = "none"
  )
```

Las Fake news suelen tener mas palabras en el título.

### % de palabras negativas

```{r}
df %>%
  ggplot(aes(x=type, y=negative, fill=type))+
  geom_boxplot() +
  labs(
    title ="% de palabras negativas",
    x = "",
    y = "% de palabras negativas"
  ) +
  theme(
    legend.position = "none"
  )
```

Las Fake news suelen tener mas palabras negativas que las reales.

## Entrenamos el modelo con Decision Tree:

```{r}

set.seed(seed_)
fake_news$id = 1:length(fake_news$id)
train_data = fake_news %>% sample_frac(0.8) 
test_data = fake_news %>% anti_join(train_data, by="id")

train_data = train_data %>% select(-id)
test_data = test_data %>% select(-id)

# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))

####ESTO ES PARA FIXEAR UN BUG RANDOM
#No se porque Pero si spliteo una vez se buguea todo y la matriz de test sale mal
#Pero si lo corro 2 veces anda perfecto 
set.seed(seed_)
fake_news$id = 1:length(fake_news$id)
train_data = fake_news %>% sample_frac(0.8) 
test_data = fake_news %>% anti_join(train_data, by="id")

train_data = train_data %>% select(-id)
test_data = test_data %>% select(-id)

# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
####

# Definimos una función para evaluar modelos con diferentes combinaciones de características
evaluate_feature_combinations <- function(data, target_col, feature_cols) {
  result <- list()
  
  for (k in 1:length(feature_cols)) {
    combinations <- combn(feature_cols, k)
    
    for (i in 1:ncol(combinations)) {
      selected_features <- c(target_col, combinations[, i])

      # Entrenamos el modelo
      model <- rpart(paste(target_col, "~", paste(combinations[, i], collapse = " + "), sep = ""), data = train_data)
      
      
      # Predecimos
      train_pred = predict(model, train_data, type = "class")
      
      predictions <- predict(model, data, type = "class")

      # Evaluamos el modelo
      confusion_matrix <- confusionMatrix(predictions, data[,target_col], positive="fake")
      train_conf_matrix = confusionMatrix(train_pred, train_data$type, positive="fake")

      # Obtenemos la matriz de confusión y las metricas
      result[[paste(combinations[, i], collapse = "+")]] <- list(
        modelo = model,
        ConfusionMatrix = confusion_matrix$table,
        Accuracy_test = sum(diag(confusion_matrix$table)) / sum(confusion_matrix$table),
        Recall_test = confusion_matrix$table[1,1] / (confusion_matrix$table[1,1] + confusion_matrix$table[2,1]),
        Train_conf = train_conf_matrix$table,
        Accuracy_train = sum(diag(train_conf_matrix$table)) / sum(train_conf_matrix$table),
        Recall_train = train_conf_matrix$table[1,1] / (train_conf_matrix$table[1,1] + train_conf_matrix$table[2,1])
      )
    }
  }
  
  return(result)
}

# Definimos los nombres de las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"  # Cambiar a la columna "type" que deseas predecir

# Llamamos a la función para evaluar las combinaciones de características en el conjunto de prueba
results <- evaluate_feature_combinations(test_data, target_column, feature_columns)
```

## Resultados Decision Tree:

```{r}
# Imprimimos los resultados (matriz de confusión y precisión) de decision tree
resultados_tree = data.frame(
  Combinacion = NA,
  Test_Accuracy = NA,
  Train_Accuracy = NA,
  Test_Recall = NA,
  Train_Recall = NA,
  Test_TP = NA,
  Test_FP =NA,
  Test_FN = NA,
  Test_TN = NA
) %>% filter(!is.na(Combinacion))

for (combination_name in names(results)) {
  res = data.frame(
    Combinacion = combination_name,
    Test_Accuracy = results[[combination_name]]$Accuracy_test,
    Train_Accuracy = results[[combination_name]]$Accuracy_train,
    Test_Recall = results[[combination_name]]$Recall_test,
    Train_Recall = results[[combination_name]]$Recall_train,
    Test_TP = results[[combination_name]]$ConfusionMatrix[1,1],
    Test_FP =results[[combination_name]]$ConfusionMatrix[1,2],
    Test_FN = results[[combination_name]]$ConfusionMatrix[2,1],
    Test_TN = results[[combination_name]]$ConfusionMatrix[2,2]
  )
  resultados_tree = rbind(resultados_tree,res)
}

kable(resultados_tree %>% arrange(-Test_Accuracy))
```

el modelo con mayor accuracy (0.63) usa las siguientes columnas:

-   title_words,

-   title_has_excl

Observamos ademas del accuracy el recall porque ,si habia un empate o estaban muy cerca, preferiamos minimizar la cantidad de falsos negativos (Que haya noticias reales que sean detectadas como fake news no es tanto problema, pero si es un problema que haya fake news que sean detectadas como reales y permitida su circulación). Aun asi el accuracy es muy bajo, se podrian agregar otras columnas del dataset para obtener mejores resultados o usar un modelo mas complejo.

### Matriz de confusión del mejor modelo

```{r}
kable(results["title_has_excl+title_words"]$`title_has_excl+title_words`$ConfusionMatrix)
```

### Grafico de decisiones del modelo.

```{r}
rpart.plot(results["title_has_excl+title_words"]$`title_has_excl+title_words`$modelo)
```

## Entrenamos el modelo con KNN:

```{r}

set.seed(seed_)

# Cargamos la librería para KNN
library(class)

# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # Seleccionamos el 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]

# Eliminamos filas con valores faltantes en ambos conjuntos
train_data <- na.omit(train_data)
test_data <- na.omit(test_data)

# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))

# Definimos una función para evaluar modelos KNN con diferentes combinaciones de características y k
evaluate_feature_combinations_knn <- function(train_data, test_data, target_col, feature_cols, k_values) {
  result <- list()
  
  for (k in 1:length(feature_cols)) {
    combinations <- combn(feature_cols, k)
    
    for (i in 1:ncol(combinations)) {
      selected_features <- c(target_col, combinations[, i])
      
      for (k_value in k_values) {
        # Entrenamos el modelo KNN
        model <- knn(train_data[, selected_features][-1], test_data[, selected_features][-1], train_data[, selected_features][, 1], k = k_value)
        
        # Evaluamos el modelo
        confusion_matrix <- table(model, test_data[, selected_features][, 1])
        
        train_pred = knn(train_data[, selected_features][-1], train_data[, selected_features][-1], train_data[, selected_features][, 1], k = k_value)
        
        train_matrix = table(train_pred, train_data[, selected_features][, 1])
        
        # Calculamos la precisión
        accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
        train_acc = sum(diag(train_matrix)) / sum(train_matrix)
        
        # Almacenamos resultados
        result[[paste(combinations[, i], collapse = "+")]]$k_value <- list(
          ConfusionMatrix = confusion_matrix,
          Test_Accuracy = accuracy,
          Train_Accuracy =train_acc,
          Recall_test = confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[2,1]),
          Train_conf = train_matrix,
        Recall_train = train_matrix[1,1] / (train_matrix[1,1] + train_matrix[2,1])
      )
        
      }
    }
  }
  
  return(result)
}

# Definimos las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"

# Definimos los valores de k que deseamos probar
k_values_to_test <- c(3, 5, 7, 9, 11)

# Llamamos a la función para evaluar combinaciones de características y diferentes valores de k en el conjunto de prueba con KNN
results_knn <- evaluate_feature_combinations_knn(train_data, test_data, target_column, feature_columns, k_values_to_test)





```

## Resultados KNN:

```{r}
# Imprimimos los resultados (matriz de confusión y precisión) de KNN para cada combinación de características y k
resultados_knn =resultados_tree = data.frame(
  Combinacion = NA,
  K=NA,
  Test_Accuracy = NA,
  Train_Accuracy = NA,
  Test_Recall = NA,
  Train_Recall = NA,
  Test_TP = NA,
  Test_FP =NA,
  Test_FN = NA,
  Test_TN = NA
) %>% filter(!is.na(Combinacion))

for (combination_name in names(results_knn)) {
  for (k_value in k_values_to_test) {
  res = data.frame(
    Combinacion = combination_name,
    K=k_value,
    Test_Accuracy = results_knn[[combination_name]]$k_value$Test_Accuracy,
    Train_Accuracy = results_knn[[combination_name]]$k_value$Train_Accuracy,
    Test_Recall = results_knn[[combination_name]]$k_value$Recall_test,
    Train_Recall = results_knn[[combination_name]]$k_value$Recall_train,
    Test_TP = results_knn[[combination_name]]$k_value$ConfusionMatrix[1,1],
    Test_FP =results_knn[[combination_name]]$k_value$ConfusionMatrix[1,2],
    Test_FN = results_knn[[combination_name]]$k_value$ConfusionMatrix[2,1],
    Test_TN = results_knn[[combination_name]]$k_value$ConfusionMatrix[2,2]
  )
  resultados_knn = rbind(resultados_knn, res)
  }
}

kable(resultados_knn %>% arrange(-Test_Accuracy))
```

La combinación de columnas title_has_excl + title_words nos dió un accuracy de 0.68 . Para todos los valores de k probados, se obtiene la misma matriz de confusión. Tomaremos el valor k=3

## Mejor modelo entre Tree vs KNN

Si bien knn dio un poco mejor el accuracy, elejimos el Tree como el mejor por tener Muchisimo mejor Recall ya que preferimos que el modelo deje pasar fake news sin detectarlas.

## Probabilidad de que articulo sea fake news:

Debido a que el algoritmo decision-tree mostró un mejor accuracy, decidimos utilizarlo para predecir la probabilidad de que un artículo sea fake si tiene 0 signos de exclamación, 15 palabras en el título y 6% de palabras con connotación negativa

```{r}
set.seed(seed_)
fake_news$id = 1:length(fake_news$id)
train_data = fake_news %>% sample_frac(0.8) 
test_data = fake_news %>% anti_join(train_data, by="id")

train_data = train_data %>% select(-id)
test_data = test_data %>% select(-id)

# Convrtimos 'title_has_excl' en tipo numérico
train_data$title_has_excl <- as.numeric(train_data$title_has_excl)


# Entrenamos el modelo utilizando solo las 3 columnas que queremos
model <- rpart(type ~ title_has_excl + title_words, data = train_data)
# Creamos un nuevo conjunto de datos con las características del nuevo artículo
new_article <- data.frame(
  title_has_excl = 0,  # No tiene signos de exclamación
  title_words = 15,    # 15 palabras en el título
  negative = 0.06      # 6% de palabras con connotaciones negativas
)

# Utilizamos el modelo de árbol de decisión para predecir la clase del nuevo artículo
predicted_class <- predict(model, new_article, type = "class")

# Calculamos la probabilidad de que el artículo sea "fake-news"
predicted_probability <- predict(model, new_article, type = "prob")

fake_news_probability <- predicted_probability[1, "fake"]

# Imprimir la clase predicha y la probabilidad
cat("Clase predicha:", predicted_class, "\n")
cat("Probabilidad de ser 'fake-news':", fake_news_probability, "\n")
```

La probabilidad de que el artículo sea fake con 0 signos de exlamación, 15 palabras en el título y 6% de palabras con connotación negativa es de 30.7%
