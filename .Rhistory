set.seed(seed_)
# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # El 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]
# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
# Definimos una función para evaluar modelos con diferentes combinaciones de características
evaluate_feature_combinations <- function(data, target_col, feature_cols) {
result <- list()
for (k in 1:length(feature_cols)) {
combinations <- combn(feature_cols, k)
for (i in 1:ncol(combinations)) {
selected_features <- c(target_col, combinations[, i])
train_data <- data[, selected_features]
# Entrenamos el modelo
model <- rpart(paste(target_col, "~", paste(combinations[, i], collapse = " + "), sep = ""), data = train_data)
# Predecimos
predictions <- predict(model, data, type = "class")
# Evaluamos el modelo
confusion_matrix <- confusionMatrix(predictions, data[, target_col])
# Obtenemos la matriz de confusión y precisión
result[[paste(combinations[, i], collapse = "-")]] <- list(
ConfusionMatrix = confusion_matrix$table,
Accuracy = confusion_matrix$overall["Accuracy"]
)
}
}
return(result)
}
# Definimos los nombres de las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"  # Cambiar a la columna "type" que deseas predecir
# Llamamos a la función para evaluar las combinaciones de características en el conjunto de prueba
results <- evaluate_feature_combinations(test_data, target_column, feature_columns)
# Imprimimos los resultados (matriz de confusión y precisión) de decision tree
for (combination_name in names(results)) {
cat("Combinación:", combination_name, "\n")
print(results[[combination_name]]$ConfusionMatrix)
cat("Accuracy:", results[[combination_name]]$Accuracy, "\n\n")
}
set.seed(seed_)
# Cargamos la librería para KNN
library(class)
# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # Seleccionamos el 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]
# Eliminamos filas con valores faltantes en ambos conjuntos
train_data <- na.omit(train_data)
test_data <- na.omit(test_data)
# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
# Definimos una función para evaluar modelos KNN con diferentes combinaciones de características y k
evaluate_feature_combinations_knn <- function(train_data, test_data, target_col, feature_cols, k_values) {
result <- list()
for (k in 1:length(feature_cols)) {
combinations <- combn(feature_cols, k)
for (i in 1:ncol(combinations)) {
selected_features <- c(target_col, combinations[, i])
for (k_value in k_values) {
# Entrenamos el modelo KNN
model <- knn(train_data[, selected_features][-1], test_data[, selected_features][-1], train_data[, selected_features][, 1], k = k_value)
# Evaluamos el modelo
confusion_matrix <- table(model, test_data[, selected_features][, 1])
# Calculamos la precisión
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Almacenamos resultados
result[[paste(combinations[, i], collapse = "-")]]$k_value <- list(
ConfusionMatrix = confusion_matrix,
Accuracy = accuracy
)
}
}
}
return(result)
}
# Definimos las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"
# Definimos los valores de k que deseamos probar
k_values_to_test <- c(3, 5, 7, 9, 11)
# Llamamos a la función para evaluar combinaciones de características y diferentes valores de k en el conjunto de prueba con KNN
results_knn <- evaluate_feature_combinations_knn(train_data, test_data, target_column, feature_columns, k_values_to_test)
# Imprimimos los resultados (matriz de confusión y precisión) de KNN para cada combinación de características y k
for (combination_name in names(results_knn)) {
for (k_value in k_values_to_test) {
cat("Combinación:", combination_name, "\n")
cat("Valor de k:", k_value, "\n")
print(results_knn[[combination_name]]$k_value$ConfusionMatrix)
cat("Accuracy:", results_knn[[combination_name]]$k_value$Accuracy, "\n\n")
}
}
# Convirtimos 'title_has_excl' en tipo numérico
train_data$title_has_excl <- as.numeric(train_data$title_has_excl)
# Entrenamos el modelo utilizando solo las 3 columnas que queremos
model <- rpart(type ~ title_has_excl + title_words + negative, data = train_data)
# Creamos un nuevo conjunto de datos con las características del nuevo artículo
new_article <- data.frame(
title_has_excl = 0,  # No tiene signos de exclamación
title_words = 15,    # 15 palabras en el título
negative = 0.06      # 6% de palabras con connotaciones negativas
)
# Utilizamos el modelo de árbol de decisión para predecir la clase del nuevo artículo
predicted_class <- predict(model, new_article, type = "class")
# Calculamos la probabilidad de que el artículo sea "fake-news"
predicted_probability <- predict(model, new_article, type = "prob")
fake_news_probability <- predicted_probability[1, "fake"]
# Imprimir la clase predicha y la probabilidad
cat("Clase predicha:", predicted_class, "\n")
cat("Probabilidad de ser 'fake-news':", fake_news_probability, "\n")
#| output: false
require(tidyverse)
require(knitr)
require(Metrics) #install.packages("Metrics")
require(rpart) #install.packages("rpart")
require(caret) #install.packages("caret")
require(class) #install.packages("class")
load("./tp2.RData")
theme_set(theme_classic())
clima_ecobici = clima_ecobici %>%
mutate(
dia_laborable = if_else(lubridate::wday(date)==1| lubridate::wday(date)==7,"No Laborable","Laborable")
)
kable(head(clima_ecobici))
clima_ecobici %>%
group_by(dia_laborable) %>%
summarise(
prom_viajes = mean(n)
)%>%
ggplot(aes(y=prom_viajes, x=dia_laborable))+
geom_col(fill='darkcyan') +
labs(
title = "Promedio de viajes por día laborable o no",
y = "Promedio de viajes",
x = "Tipo de día"
)
clima_ecobici %>%
mutate(
lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
) %>%
ggplot(aes(x=lluvias, y=n))+
geom_boxplot(fill="darkcyan")+
labs(
title = "Cant. Viajes segun precipitación",
x= "Precipitación (mm)",
y= "Viajes",
legend=""
) +
theme(legend.title=element_blank())
#| echo: false
kable(clima_ecobici %>%
mutate(
lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
n_laborable = if_else(dia_laborable=="Laborable", n,0),
) %>%
group_by(lluvias)%>%
summarise(
prom_viajes_por_dia = mean(n),
))
clima_ecobici %>%
mutate(
lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
) %>%
filter(dia_laborable == "Laborable") %>%
ggplot(aes(x=lluvias, y=n))+
geom_boxplot(fill="#F8766D")+
labs(
title = "Cant. Viajes segun precipitación",
subtitle = "Días Laborables",
x= "Precipitación (mm)",
y= "Viajes",
legend=""
) +
theme(legend.title=element_blank())
clima_ecobici %>%
mutate(
lluvias = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
) %>%
filter(dia_laborable != "Laborable") %>%
ggplot(aes(x=lluvias, y=n))+
geom_boxplot(fill="#619CFF")+
labs(
title = "Cant. Viajes segun precipitación",
subtitle = "Días No Laborables",
x= "Precipitación (mm)",
y= "Viajes",
legend=""
) +
theme(legend.title=element_blank())
clima_ecobici %>%
ggplot(aes(x=pres,y=n,color=dia_laborable))+
geom_smooth(se=T, method = 'lm') +
geom_point() +
labs(
y = "Cantidad de viajes",
x = "Presión Atmosféroca (hPa)",
title = "Cant. de Viajes en función de la Presión"
)+
theme(legend.title=element_blank())
clima_ecobici %>%
ggplot(aes(x=tmin,y=n,color=dia_laborable))+
geom_smooth(se=T, method = 'lm') +
geom_point() +
labs(
y = "Cantidad de viajes",
x = "Temp. Mínima (°C)",
title = "Cant. de Viajes en función de la Temp. Mínima"
)+
theme(legend.title=element_blank())
clima_ecobici %>%
ggplot(aes(x=tavg,y=n,color=dia_laborable))+
geom_smooth(se=T, method = 'lm') +
geom_point() +
labs(
y = "Cantidad de viajes",
x = "Temp. Promedio (°C)",
title = "Cant. de Viajes en función de la Temp. Promedio"
)+
theme(legend.title=element_blank())
clima_ecobici %>%
ggplot(aes(x=tmax,y=n,color=dia_laborable))+
geom_smooth(se=T, method = 'lm') +
geom_point() +
labs(
y = "Cantidad de viajes",
x = "Temp. Máxima (°C)",
title = "Cant. de Viajes en función de la Temp. Máxima"
)+
theme(legend.title=element_blank())
clima_ecobici %>%
ggplot(aes(x=wspd,y=n,color=dia_laborable))+
geom_smooth(se=T, method = 'lm') +
geom_point() +
theme(legend.title=element_blank()) +
labs(
x="Velocidad del Viento (km/h)",
y = "Cantidad de viajes",
title = "Cant. de Viajes en función de la Vel. del Viento"
)
r2 = function(y_actual,y_predict){
return(cor(y_actual,y_predict)^2)
}
#retorna los resultados del modelo
eval_formula = function(nombre_modelo, formula, x_train, x_test, y_train, y_test){
modelo = lm({{formula}}, data = x_train)
train_preds = predict(modelo, x_train)
test_preds = predict(modelo, x_test)
return(
data.frame(
nombre_exp = nombre_modelo,
formula = formula,
train_RMSE = rmse(y_train, train_preds),
train_r2 = r2(y_train, train_preds),
test_RMSE = rmse(y_test, test_preds),
test_r2 = r2(y_test, test_preds)
)
)
}
#retorna un dataframe con los nombres de las columnas a usar normalizados
#asi no escribimos tanto
preprocess_df = function(df, target, colum_1, colum_2){
return(
df %>%
# tuve que poner el all_of pq me tiraba warnings
select(all_of({{target}}), all_of({{colum_1}}), all_of({{colum_2}})) %>%
rename(
"y"=target,
"col_1"=colum_1,
"col_2"=colum_2)
)
}
#creo la lista de formulas
formulas = c(
"y ~ col_1", #caso mas simples
"y ~ col_2",
"y ~ col_1 + col_2",  #combinaciones
"y ~ col_1 * col_2",
"y ~ col_1 * col_2 + col_1",
"y ~ col_1 * col_2 + col_2",
"y ~ col_1 * col_2 + col_1 + col_2"
)
#Creo la funcion que engloba todo
probar_experimento = function(nombre, seed, target, x1, x2,df){
data = preprocess_df(df, target, x1, x2)
set.seed(seed)
#train test split
data$index = 1:length(data$y)
train = data %>% sample_frac(0.8)
test = data %>% anti_join(train, by="index")
# guardo los resultados en una tabla
res = data.frame(
nombre_exp = NA,
formula = NA,
train_RMSE = NA,
train_r2 = NA,
test_RMSE = NA,
test_r2 = NA,
seed = NA,
col_1 = NA,
col_2 = NA
) %>% filter(!is.na(seed))
#pruebo cada forumula
for(formula in formulas){
exp_res = eval_formula(
nombre, formula,
train,
test,
train$y,
test$y
)
exp_res$seed = seed
exp_res$col_1 = x1
exp_res$col_2 = x2
res = rbind(res, exp_res)
}
#devuelvo los resultados
return(res)
}
df = clima_ecobici %>%
mutate(
lluvias_binned = cut(prcp, breaks= c(0,1,20,50,300), labels=c("0","1-20","20-50","50+"), include.lowest=T),
llovio = if_else(prcp > 0, T, F)
)
resultados = data.frame(
nombre_exp = NA,
formula = NA,
train_RMSE = NA,
train_r2 = NA,
test_RMSE = NA,
test_r2 = NA,
seed = NA
) %>% filter(!is.na(seed))
seed_ = 42
resultados = rbind(resultados, probar_experimento(
"Dia laborable Presion",
seed_, "n", "dia_laborable", "pres", df))
resultados = rbind(resultados, probar_experimento(
"Dia laborable pptacion",
seed_, "n", "dia_laborable", "prcp", df))
resultados = rbind(resultados, probar_experimento(
"Dia laborable llueve o no",
seed_, "n", "dia_laborable", "llovio", df))
resultados = rbind(resultados, probar_experimento(
"Dia laborable lluvia binned",
seed_, "n", "dia_laborable", "lluvias_binned", df))
kable(resultados %>% arrange(-test_r2))
df = fake_news%>%
select(type,title_has_excl,title_words, negative)
kable(head(df))
df %>%
mutate(
exlamacion = if_else(title_has_excl,'Tiene Signo de Exclamación', 'No Tiene Signo de Exclamación')
) %>%
ggplot(aes(fill=type,x=exlamacion)) +
theme(legend.title=element_blank()) +
labs(
x="",
y = "Cantidad de Noticias",
title = "Cantidad de noticias con simbolos de exclamación en el título"
) +
geom_bar()
df %>%
ggplot(aes(x=type, y=title_words, fill=type)) +
geom_boxplot() +
labs(
title ="Cantidad de palabras en el título",
x = "",
y = "Cantidad de palabras"
) +
theme(
legend.position = "none"
)
df %>%
ggplot(aes(x=type, y=negative, fill=type))+
geom_boxplot() +
labs(
title ="% de palabras negativas",
x = "",
y = "% de palabras negativas"
) +
theme(
legend.position = "none"
)
set.seed(seed_)
# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # El 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]
# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
# Definimos una función para evaluar modelos con diferentes combinaciones de características
evaluate_feature_combinations <- function(data, target_col, feature_cols) {
result <- list()
for (k in 1:length(feature_cols)) {
combinations <- combn(feature_cols, k)
for (i in 1:ncol(combinations)) {
selected_features <- c(target_col, combinations[, i])
train_data <- data[, selected_features]
# Entrenamos el modelo
model <- rpart(paste(target_col, "~", paste(combinations[, i], collapse = " + "), sep = ""), data = train_data)
# Predecimos
predictions <- predict(model, data, type = "class")
# Evaluamos el modelo
confusion_matrix <- confusionMatrix(predictions, data[, target_col])
# Obtenemos la matriz de confusión y precisión
result[[paste(combinations[, i], collapse = "-")]] <- list(
ConfusionMatrix = confusion_matrix$table,
Accuracy = confusion_matrix$overall["Accuracy"]
)
}
}
return(result)
}
# Definimos los nombres de las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"  # Cambiar a la columna "type" que deseas predecir
# Llamamos a la función para evaluar las combinaciones de características en el conjunto de prueba
results <- evaluate_feature_combinations(test_data, target_column, feature_columns)
# Imprimimos los resultados (matriz de confusión y precisión) de decision tree
for (combination_name in names(results)) {
cat("Combinación:", combination_name, "\n")
print(results[[combination_name]]$ConfusionMatrix)
cat("Accuracy:", results[[combination_name]]$Accuracy, "\n\n")
}
set.seed(seed_)
# Cargamos la librería para KNN
library(class)
# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # Seleccionamos el 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]
# Eliminamos filas con valores faltantes en ambos conjuntos
train_data <- na.omit(train_data)
test_data <- na.omit(test_data)
# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
# Definimos una función para evaluar modelos KNN con diferentes combinaciones de características y k
evaluate_feature_combinations_knn <- function(train_data, test_data, target_col, feature_cols, k_values) {
result <- list()
for (k in 1:length(feature_cols)) {
combinations <- combn(feature_cols, k)
for (i in 1:ncol(combinations)) {
selected_features <- c(target_col, combinations[, i])
for (k_value in k_values) {
# Entrenamos el modelo KNN
model <- knn(train_data[, selected_features][-1], test_data[, selected_features][-1], train_data[, selected_features][, 1], k = k_value)
# Evaluamos el modelo
confusion_matrix <- table(model, test_data[, selected_features][, 1])
# Calculamos la precisión
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Almacenamos resultados
result[[paste(combinations[, i], collapse = "-")]]$k_value <- list(
ConfusionMatrix = confusion_matrix,
Accuracy = accuracy
)
}
}
}
return(result)
}
# Definimos las columnas de características y el objetivo
feature_columns <- c("title_has_excl", "title_words", "negative")
target_column <- "type"
# Definimos los valores de k que deseamos probar
k_values_to_test <- c(3, 5, 7, 9, 11)
# Llamamos a la función para evaluar combinaciones de características y diferentes valores de k en el conjunto de prueba con KNN
results_knn <- evaluate_feature_combinations_knn(train_data, test_data, target_column, feature_columns, k_values_to_test)
# Imprimimos los resultados (matriz de confusión y precisión) de KNN para cada combinación de características y k
for (combination_name in names(results_knn)) {
for (k_value in k_values_to_test) {
cat("Combinación:", combination_name, "\n")
cat("Valor de k:", k_value, "\n")
print(results_knn[[combination_name]]$k_value$ConfusionMatrix)
cat("Accuracy:", results_knn[[combination_name]]$k_value$Accuracy, "\n\n")
}
}
set.seed(seed_)
# Dividimos el DataFrame en conjuntos de entrenamiento y prueba
n <- nrow(fake_news)
test_indices <- sample(1:n, 0.2 * n)  # El 20% de los datos para pruebas
train_data <- fake_news[-test_indices, ]
test_data <- fake_news[test_indices, ]
# Convertimos la columna "type" a factor con los mismos niveles en ambos conjuntos
train_data$type <- factor(train_data$type, levels = unique(fake_news$type))
test_data$type <- factor(test_data$type, levels = unique(fake_news$type))
# Convrtimos 'title_has_excl' en tipo numérico
train_data$title_has_excl <- as.numeric(train_data$title_has_excl)
# Entrenamos el modelo utilizando solo las 3 columnas que queremos
model <- rpart(type ~ title_has_excl + title_words + negative, data = train_data)
# Creamos un nuevo conjunto de datos con las características del nuevo artículo
new_article <- data.frame(
title_has_excl = 0,  # No tiene signos de exclamación
title_words = 15,    # 15 palabras en el título
negative = 0.06      # 6% de palabras con connotaciones negativas
)
# Utilizamos el modelo de árbol de decisión para predecir la clase del nuevo artículo
predicted_class <- predict(model, new_article, type = "class")
# Calculamos la probabilidad de que el artículo sea "fake-news"
predicted_probability <- predict(model, new_article, type = "prob")
fake_news_probability <- predicted_probability[1, "fake"]
# Imprimir la clase predicha y la probabilidad
cat("Clase predicha:", predicted_class, "\n")
cat("Probabilidad de ser 'fake-news':", fake_news_probability, "\n")
